\chapter{Programming}\label{chap:prog}
\begin{overview}
  The software developed for this project is described in this chapter.
  Attention is given to the following aspects;
  \begin{itemize}
    \item software design,
    \item programming language,
    \item external tools,
    \item selected code overviews and
    \item user interaction and feedback.
  \end{itemize}
\end{overview}

\section{Assumptions}
Certain assumptions are made about the systems investigated.
This serves to define the scope of the project and aids in the mathematical rigour of the methods.
\begin{itemize}
\item Steady-state models are used.
  These models result in real matrices and allow for strictly linear transformation of spaces.
\item Only linear constraints are considered.
  This allows for half-space geometry to be used and ensures convexity of intersections (along with the assumption of steady-state gain models).
\item The convexity of all spaces are assumed.
  This allows the use of minimum vertex descriptions.
\end{itemize}
It should be noted that this is a subset of the available problems.
It is by no means implied that rigorous mathematical methods are only possible for this given subset.

Note that when reference is made to a ``constraint set'', all the half-spaces comprising the set as well as the feasible region (of the set) is implied.

\section{Programming language}
The routines developed for this project was done using the Python programming language.
The SciPy and NumPy modules provide the majority of the mathematical functions used.
The programs were compiled in Linux (Ubuntu 10.4) and this is at present the only supported platform.

\section{Qhull}\label{sec:qhull}
Extensive use is made of the \qhull algorithm \citep{qhull} for the calculation of normals, vertices and hypervolumes.
This algorithm was selected on the basis of its multidimentional functionality and the availability of Unix binaries.
Other Python libraries were considered but deemed insufficient, the most prominent routines being;
\begin{itemize}
\item The \texttt{spatial} module of SciPy contains a Python implementation of the \qhull algorithm but does not currently allow for volume and normal calculation.
\item The CGAL-Python project \citep{cgal} provides Python bindings to the Computational Geometry Algorithms Library (CGAL) but does not more than 3 dimensions.
\end{itemize}

For this project, the \qhull algorithm is directly implemented from its Unix binaries.
A Python subprocess call is used, with communication to/from \qhull by standard input and standard output.
It should be noted that the \qhull algorithm works with vertices and conversion between vertices and half-spaces are done throughout the code.

\section{Constraint set class}
\label{sec:conclass}
A Python class, \texttt{ConSet}, was created to handle constraint sets.
Commonly used attributes of these sets were added as properties of the class and commonly used operations were added as methods.

\subsection{Constructors}
Constraint sets can be constructed from the set of constraints or from the vertices of their feasible region.
For construction from vertices, the set is assumed to be closed and the corresponding constraints are generated accordingly.
Open sets can occur when constructing from constraints as the half-spaces comprising the set are predefined.
Open sets are flagged as erroneous and construction does not proceed.

\subsection{Methods}
The methods of the \texttt{ConSet} class are briefly discussed below.

\subsubsection{Volume}
The \qhull algorithm is used to calculate the hypervolume of the constrain set.
%% MEMOIZE VOLUME and expand

\subsubsection{Space conversion}
The process model is used when converting from the input space to the output space (or vice versa).
When using a steady-state model (real matrix of gains) this results in a matrix multiplication.
Therefore, the output of this operation is a linear transformation of the vertices of the initial constraint set.  

\subsubsection{Intersections}
When the intersection of two constraint sets need to be calculated (as is the case with the AOS and the DOS), a method of superfluous constraints is used.
The constraints of both sets are combined into a single set, the feasible region of this set represents the intersection of the two initial sets.

\subsubsection{Checks}
A check to determine whether one constraint set is contained within another was added to the class.
The \texttt{allinside} method checks whether all vertices of a constraint set satisfy the constraints of another set.
With the enforcement of convexity, this is a sufficient test to ensure that the set is indeed contained.

When a set is not contained within another set, a measure for ``outside-ness'' is generated.
For each constraint of the outer set, the perpendicular distance of all vertices violating that constraint is calculated and summed.
% USE A BETTER WORD THAN OUTSIDE-NESS

\section{Constraint/Vertex conversions}\label{sec:con2vert}
As mentioned in section \ref{sec:qhull}, most calculations are done using the vertices of a constraint set.
Methods to convert from vertices to constraints (and vice versa) are included in this program.

For conversion from vertices to constraints, the normals of the convex hull of the set of vertices is calculated.
These normals satisfy $A\vect{x} \leq -\vect{b}$ \citep{qhulldocs} and from this the constraints can be calculated directly.

The conversion from constraints to vertices is slightly more complex.
Code by \citet{con2vert} was converted to Python code.
A primal-dual polytope method is used to calculate the resulting vertices.
This method can produce duplicate vertices; the output is therefore checked and duplicates removed.
% Add math reference

\section{Constraint set fitting}\label{sec:confit}
The fitting of a constraint set within another can be used to reduce the control problem.
Typically, a set with fewer constraints is fitted into an existing set whilst still maintaining the largest possible operating region.
In mathematical terms, the problem consists of fitting the largest volume polytope (with a specified number of faces) within another polytope (with more faces than the fitted polytope).

This seemingly trivial optimization problem is not covered in this form in available literature.
A similar problem is that of optimized diamond cutting \citep{diamondcut} which maximises the volume of a diamond within a rough stone.
This method allows for rotation, translation and scaling, but uses a fixed shape for the diamond (i.e. all aspect ratios of the fitted shape stays constant).
Another well considered problem in literature is the packing problem, which involves packing the maximum amount of shapes in a given shape (or container).
Again, the shapes considered in this problem are of fixed dimensions (and aspect ratios), but the largest dissimilarity is that a number of shapes are fitted, not just a single one.

\subsection{Problem formulation}
Each half-space -- or the faces of a shape -- represents a constraint.
The constraint set can therefore be described by equation \ref{eq:cset}, where $A$ is the half-plane slope matrix and $\vect{b}$ the offsets.
\begin{equation}
  \label{eq:cset}
  A\vect{x} \leq \vect{b}
\end{equation}
In $n$ dimensions, the general problem now becomes; 
\begin{itemize}
  \item given a polytope, $P_o$, having $k$ faces,
  \item fit a polytope, $P_i$, with $l$ faces (where $n+1 \leq l \le k$) within $P_o$, and
  \item maximise the volume of $P_i$.
\end{itemize} 
Note that with the specification of the number of faces, the dimensions of $A$ and $\vect{b}$ for both $P_i$ and $P_o$ are fixed.
For $P_o$, $A$ is an $k \times n$ matrix and $\vect{b}$ is a $k \times 1$ vector.
For $P_i$, $A$ is an $l \times n$ matrix and $\vect{b}$ is a $l \times 1$ vector.

Expressed as a minimization problem, the fitting of an arbitrary shape  becomes equation \ref{eq:arbvolmin}.
\begin{align}
  \label{eq:arbvolmin}
    \min_{A,~\vect{b}}~~&\text{-volume}_{P_i}\\
    \text{s.t.}~~~~ &P_i \subset P_o \notag \\
                    &P_i \text{~and~} P_o \text{~convex} \notag
\end{align}
For the fitting of a rectangular constraint set (high/low limits), equation \ref{eq:arbvolmin} reduces to equation \ref{eq:recvolmin}.
In this description $\vect{b}$ is the only input variable (of size $2n \times 1$) and $I$ is an $n\times n$ identity matrix.
\begin{align}
  \label{eq:recvolmin}
    \min_{\vect{b}}~~&\text{-volume}_{P_i}\\
    \text{s.t.}~~~~ &A = \bpm I \\ -I \epm \notag \\
                    &P_i \subset P_o \notag \\
                    &P_i \text{~and~} P_o \text{~convex} \notag
\end{align}

\subsubsection{Face formulation}
The minimization problems formulated in equations \ref{eq:arbvolmin} and \ref{eq:recvolmin} are based on the faces $P_i$.
$A$ and $\vect{b}$ are the input variables for the minimization.
From these two variables the vertices of $P_i$ are calculated and subsequently the volume.

The advantages of using this formulation are;
\begin{itemize}
\item It is a more rigorous approach, as the constraints that comprise the set are actively changed to find the optimum.
\item By fixing the sizes of $A$ and $\vect{b}$, the specified number of constraints to fit is ensured.
\item With the use of only linear constraints, the convexity of $P_i$ is ensured.
This results from the feasible region of half-spaces being strictly convex.
\end{itemize}

This formulation, although rigorous, suffers from some problems in the execution thereof;
\begin{itemize}
\item Inconsistent gradient information is generated when checking if $P_i$ is inside $P_o$.
This arises from the fact that concept of being ``inside'' one another is not defined for two half-spaces (with the exception of parallel half-spaces).
\item Superfluous degrees of freedom are present, as the complete $A$ matrix and $\vect{b}$ are solved for.
There is effectively 1 false degree of freedom for each constraint of $P_i$.
\item Due to $A$ and $\vect{b}$ begin fully changeable, shape inversion can occur.
This occurs when constraints move in such a way that an open set generated.
Figure \ref{fig:shapeinversion} illustrates this concept.
\item A scaling-type problem presents itself with the calculation of the volume of $P_i$.
This come from the fact that the volume of $P_i$ is the same for $[A,~ \vect{b}]$ and $[zA,~z\vect{b}]$ where $z\in \mathbb{R}$.
Very large elements in the rows of $A$ (and their corresponding elements in $\vect{b}$) dramatically reduces the sensitivity of objective functions.
This problem can, however, be overcome by adding a constraint to the solver used to keep the norm of $\vect{b}$ at a set value.
\end{itemize}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=8cm]{graph/shapeinversion}
  \caption[Shape inversion example]{Shape inversion due to the movement of constraints (half-space normals arrows are shown with arrows).}
  \label{fig:shapeinversion}
\end{figure}

\subsubsection{Vertex formulation}
Another possibility was to express the problem in terms of the vertices that form the convex hull of the constraint set.
For this formulation, equation \ref{eq:arbvolmin} needs to be redefined in terms of the vertices, as shown in equation \ref{eq:arbvolminverts}
\begin{align}
  \label{eq:arbvolminverts}
    \min_{v}~~&\text{-volume}_{P_i}\\
    \text{s.t.}~~~~ &P_i \subset P_o \notag \\
                    &P_i \text{~and~} P_o \text{~convex} \notag
\end{align}
where $\vect{v}$ is all the vertices of $P_i$.
It needs to be noted that $A$ and $\vect{b}$ will now only result from the final optimized $P_i$.

The vertex based formulation has the following advantages;
\begin{itemize}
  \item This approach is more intuitive as the fitting problem, conceptually, involves moving the vertices of $P_i$ to the faces of $P_o$.
  \item Checking that $P_i$ is inside $P_o$ is now a direct operation, as vertices don't need to be calculated from $A$ and $\vect{b}$ first.
  \item When a measure of containment needs to be generated, consistent gradient information can be expressed in terms of each vertex of $P_i$.
\end{itemize}

Most of the problems with the vertex based method stems from the movement of vertices to the inside of the convex hull of $P_i$ during the solving of the problem.
These internal points are now no longer vertices, but are still considered in the optimization.
This formulation was abandoned in this project due to the following disadvantages in its implementation;
\begin{itemize}
  \item A clear correlation between the number of vertices and the number of faces on a shape does not exist.
Figure \ref{fig:vertsvsfaces} illustrates this concept for two 6-faced, 3 dimensional shapes.
This is a major problem when the amount of faces (constraints) on $P_i$ needs to be specified.
  \item A slightly different problem than the one mentioned above -- the number of faces on $P_i$ is determined by the final optimised vertices.
Internal points and duplicate vertices in the solution will cause the number of faces to decrease.
Therefore, specification of a set number of faces becomes nearly impossible.
  \item Enforcing convexity becomes a problem when vertices are used directly.
This is caused by the movement of vertices inside the convex hull of $P_i$.
If all points are to be vertices by definition, non-convex shapes are generated.
The use of the \qhull algorithm to calculate the volume now becomes invalid. 
  \item Another problem with internal points is during the calculation of the volume of $P_i$.
The perturbation of internal points have no effect on the volume (as only the convex hull is considered).
This results in decreased sensitivity of objective functions.
\end{itemize}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=8cm]{graph/vertsvsfaces}
  \caption[The unclear correlation between number of faces and vertices]{A cube and a pentagonal pyramid in 3 dimensions -- both shapes have 6 faces, but differ in their amount of vertices (8 and 6  respectively).}
  \label{fig:vertsvsfaces}
\end{figure}

\subsection{Optimization}

\subsection{Starting point generation}

\subsection{Rectangle fitting}

\subsection{Shape fitting}





% Local Variables:
% TeX-master: "AHC_thesis"
% End: